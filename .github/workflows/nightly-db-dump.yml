name: nightly-db-dump

on:
  workflow_dispatch:
  schedule:
    - cron: "0 4 * * *"   # 04:00 UTC daily

jobs:
  dump:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Connectivity + dump via Docker (Postgres 17)
        id: db
        shell: bash
        env:
          # DB (read-only user)
          PGPASSWORD: ${{ secrets.DB_PASSWORD }}
          DB_HOST:     ${{ secrets.DB_HOST }}
          DB_PORT:     ${{ secrets.DB_PORT }}
          DB_USER:     ${{ secrets.DB_USER }}       # backup_user
          DB_NAME:     ${{ secrets.DB_NAME }}       # postgres

          # Crypto + S3
          BACKUP_PASSPHRASE: ${{ secrets.BACKUP_PASSPHRASE }}
          AWS_REGION:        ${{ secrets.AWS_REGION }}
          S3_BUCKET:         ${{ secrets.S3_BUCKET }}

          # Slack
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        run: |
          set -euo pipefail
          : "${DB_HOST:?Missing DB_HOST}"; : "${DB_USER:?Missing DB_USER}"; : "${DB_NAME:?Missing DB_NAME}"
          : "${PGPASSWORD:?Missing DB_PASSWORD}"; DB_PORT="${DB_PORT:-5432}"

          echo "Connectivity check..."
          docker run --rm -e PGPASSWORD="$PGPASSWORD" -e PGSSLMODE=require \
            postgres:17-alpine \
            psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -c "SELECT 1;"

          echo "Discover RLS tables to exclude..."
          RLS_TABLES=$(docker run --rm -e PGPASSWORD="$PGPASSWORD" -e PGSSLMODE=require \
            postgres:17-alpine \
            psql -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" -At -c \
            "SELECT quote_ident(n.nspname)||'.'||quote_ident(c.relname)
               FROM pg_class c JOIN pg_namespace n ON n.oid=c.relnamespace
              WHERE c.relkind='r' AND c.relrowsecurity=true;")
          EXCLUDE_FLAGS=""
          if [ -n "${RLS_TABLES}" ]; then
            while IFS= read -r t; do
              case "$t" in auth.*|storage.*|realtime.*) continue;; esac
              EXCLUDE_FLAGS+=" --exclude-table-data='${t}'"
            done <<< "$RLS_TABLES"
          fi

          ts=$(date -u +'%Y%m%dT%H%M%SZ'); outfile="dump_${ts}.pgc"
          echo "Dump (read-only) → $outfile"
          docker run --rm -e PGPASSWORD="$PGPASSWORD" -e PGSSLMODE=require -v "$PWD":/work \
            postgres:17-alpine sh -c "
              pg_dump -h \"$DB_HOST\" -p \"$DB_PORT\" -U \"$DB_USER\" -d \"$DB_NAME\" \
                      --format=custom --no-owner --no-privileges \
                      --exclude-schema=auth --exclude-schema=storage --exclude-schema=realtime \
                      $EXCLUDE_FLAGS \
                      --file \"/work/$outfile\"
            "

          echo "Encrypting..."
          : "${BACKUP_PASSPHRASE:?Missing BACKUP_PASSPHRASE}"
          gpg --batch --yes --passphrase "$BACKUP_PASSPHRASE" --symmetric --cipher-algo AES256 "$outfile"
          shasum -a 256 "$outfile.gpg" > "$outfile.gpg.sha256"

          echo "outfile=$outfile.gpg" >> "$GITHUB_OUTPUT"
          echo "checksum=$outfile.gpg.sha256" >> "$GITHUB_OUTPUT"

      - name: Configure AWS
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ secrets.AWS_REGION }}

      - name: Upload to S3
        env:
          S3_BUCKET: ${{ secrets.S3_BUCKET }}
        run: |
          set -euo pipefail
          aws s3 cp "${{ steps.db.outputs.outfile }}" "s3://${S3_BUCKET}/nightly/${{ steps.db.outputs.outfile }}"
          aws s3 cp "${{ steps.db.outputs.checksum }}" "s3://${S3_BUCKET}/nightly/${{ steps.db.outputs.checksum }}"

      - name: Upload artifacts (optional)
        uses: actions/upload-artifact@v4
        with:
          name: pg-dump-nightly
          path: |
            ${{ steps.db.outputs.outfile }}
            ${{ steps.db.outputs.checksum }}

      - name: Notify Slack (success)
        if: success()
        run: |
          [ -z "${SLACK_WEBHOOK_URL:-}" ] && exit 0
          curl -X POST -H 'Content-type: application/json' --data \
          "$(jq -n --arg t 'Nightly DB backup ✅' --arg f '${{ steps.db.outputs.outfile }}' \
             --arg b '${{ secrets.S3_BUCKET }}' \
             '{text: ($t + " uploaded to s3://" + $b + "/nightly/" + $f)}')" \
          "$SLACK_WEBHOOK_URL"

      - name: Notify Slack (failure)
        if: failure()
        run: |
          [ -z "${SLACK_WEBHOOK_URL:-}" ] && exit 0
          curl -X POST -H 'Content-type: application/json' --data '{"text":"Nightly DB backup ❌ failed"}' "$SLACK_WEBHOOK_URL"
